{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "magnetic-disposal",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outdoor-fantasy",
   "metadata": {},
   "source": [
    "## image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "involved-lawrence",
   "metadata": {},
   "source": [
    "```Python\n",
    "autokeras.image_dataset_from_directory(\n",
    "    directory,\n",
    "    batch_size=32,\n",
    "    color_mode=\"rgb\",\n",
    "    image_size=(256, 256),\n",
    "    interpolation=\"bilinear\",\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cultural-associate",
   "metadata": {},
   "source": [
    "从目录中的图像文件生成 tf.data.Dataset。 如果您的目录结构是："
   ]
  },
  {
   "cell_type": "raw",
   "id": "cubic-fields",
   "metadata": {},
   "source": [
    "main_directory/\n",
    "...class_a/\n",
    "......a_image_1.jpg\n",
    "......a_image_2.jpg\n",
    "...class_b/\n",
    "......b_image_1.jpg\n",
    "......b_image_2.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-delta",
   "metadata": {},
   "source": [
    "然后调用 image_dataset_from_directory(main_directory) 将返回一个 tf.data.Dataset，它从子目录 class_a 和 class_b 中生成批量图像，以及标签“class_a”和“class_b”。\n",
    "\n",
    "支持的图片格式：jpeg、png、bmp、gif。 动画 gif 被截断到第一帧。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-neutral",
   "metadata": {},
   "source": [
    "### 参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ultimate-sierra",
   "metadata": {},
   "source": [
    "* `directory str`：数据所在的目录。如果标签是“推断的”，它应该包含子目录，每个子目录包含一个类的图像。否则，目录结构将被忽略。\n",
    "* `batch_size` int：批量数据的大小。默认值：32。\n",
    "* `color_mode` str：“灰度”、“rgb”、“rgba”之一。默认值：“RGB”。图像是否将转换为具有 1、3 或 4 个通道。\n",
    "* `image_size` Tuple[int, int]：从磁盘读取图像后调整图像大小的大小。默认为 (256, 256)。由于管道处理必须具有相同大小的批量图像，因此必须提供此信息。\n",
    "* `interpolation` str：字符串，调整图像大小时使用的插值方法。默认为双线性。支持双线性、最近、双三次、面积、lanczos3、lanczos5、gaussian、mitchelcubic。\n",
    "* `shuffle bool`：是否对数据进行洗牌。默认值：真。如果设置为 False，则按字母数字顺序对数据进行排序。\n",
    "* `seed` Optional[int]：用于改组和转换的可选随机种子。\n",
    "* `validation_split` Optional[float]: 0 到 1 之间的可选浮点数，保留用于验证的数据的一部分。\n",
    "* `subset` 可选[str]：“训练”或“验证”之一。仅在设置了validation_split 时使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polish-bulletin",
   "metadata": {},
   "source": [
    "### 返回值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exciting-magazine",
   "metadata": {},
   "source": [
    "一个 tf.data.Dataset 对象，它产生一个元组（文本、标签），其中图像具有形状（batch_size、image_size[0]、image_size[1]、num_channels），其中标签具有形状（batch_size，）和 tf 类型。 细绳。 \n",
    "- 如果 color_mode 为灰度，则图像张量中有 1 个通道。 \n",
    "- 如果 color_mode 为 rgb，则图像张量中有 3 个通道。 \n",
    "- 如果 color_mode 为 rgba，则图像张量中有 4 个通道。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-assessment",
   "metadata": {},
   "source": [
    "## text_dataset_from_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "steady-detector",
   "metadata": {},
   "source": [
    "```Python\n",
    "autokeras.text_dataset_from_directory(\n",
    "    directory, batch_size=32, max_length=None, shuffle=True, seed=None, validation_split=None, subset=None\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frozen-tragedy",
   "metadata": {},
   "source": [
    "从目录中的文本文件生成 tf.data.Dataset。\n",
    "\n",
    "如果您的目录结构是："
   ]
  },
  {
   "cell_type": "raw",
   "id": "organic-proceeding",
   "metadata": {},
   "source": [
    "main_directory/\n",
    "...class_a/\n",
    "......a_text_1.txt\n",
    "......a_text_2.txt\n",
    "...class_b/\n",
    "......b_text_1.txt\n",
    "......b_text_2.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diagnostic-grenada",
   "metadata": {},
   "source": [
    "然后调用 text_dataset_from_directory(main_directory) 将返回一个 tf.data.Dataset，该数据集从子目录 class_a 和 class_b 中生成批量文本，以及标签“class_a”和“class_b”。\n",
    "\n",
    "目前仅支持 .txt 文件。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlling-stage",
   "metadata": {},
   "source": [
    "### 参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "juvenile-indiana",
   "metadata": {},
   "source": [
    "* `directory` str：数据所在的目录。 如果标签是“推断的”，它应该包含子目录，每个子目录包含一个类的文本文件。 否则，目录结构将被忽略。\n",
    "* `batch_size` int：批量数据的大小。 默认为 32。\n",
    "* `max_length` 可选[int]：文本字符串的最大大小。 超过此长度的文本将被截断为 max_length。\n",
    "* `shuffle` bool：是否对数据进行洗牌。 默认值：真。 如果设置为 False，则按字母数字顺序对数据进行排序。\n",
    "* `seed` Optional[int]：用于改组和转换的可选随机种子。\n",
    "* `validation_split` Optional[float]: 0 到 1 之间的可选浮点数，保留用于验证的数据的一部分。\n",
    "* `subset` 可选[str]：“训练”或“验证”之一。 仅在设置了validation_split 时使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acting-saudi",
   "metadata": {},
   "source": [
    "### 返回值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medical-sender",
   "metadata": {},
   "source": [
    "一个 tf.data.Dataset 对象，它产生一个元组（文本、标签），其中都有形状 (batch_size,) 和 tf.string 类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-kuwait",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
