{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "valid-rating",
   "metadata": {},
   "source": [
    "# 文本分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "literary-charge",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_files\n",
    "\n",
    "import autokeras as ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "intense-partnership",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "\n",
    "if gpus:\n",
    "    gpu0 = gpus[1] #如果有多个GPU，仅使用第0个GPU\n",
    "    tf.config.experimental.set_memory_growth(gpu0, True) #设置GPU显存用量按需使用\n",
    "    # 或者也可以设置GPU显存为固定使用量(例如：4G)\n",
    "    #tf.config.experimental.set_virtual_device_configuration(gpu0,\n",
    "    #    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)]) \n",
    "    tf.config.set_visible_devices([gpu0],\"GPU\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "stone-april",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relevant-lounge",
   "metadata": {},
   "source": [
    "## 一个简单的例子"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "logical-romania",
   "metadata": {},
   "source": [
    "第一步是准备数据。 这里我们以 IMDB 数据集为例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "classical-paragraph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
      "84131840/84125825 [==============================] - 257s 3us/step\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.keras.utils.get_file(\n",
    "    fname=\"aclImdb.tar.gz\",\n",
    "    origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\",\n",
    "    extract=True,\n",
    ")\n",
    "\n",
    "# set path to dataset\n",
    "IMDB_DATADIR = os.path.join(os.path.dirname(dataset), \"aclImdb\")\n",
    "\n",
    "classes = [\"pos\", \"neg\"]\n",
    "train_data = load_files(\n",
    "    os.path.join(IMDB_DATADIR, \"train\"), shuffle=True, categories=classes\n",
    ")\n",
    "test_data = load_files(\n",
    "    os.path.join(IMDB_DATADIR, \"test\"), shuffle=False, categories=classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "unavailable-deployment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "forbidden-realtor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "thousand-tours",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "relative-canada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n",
      "(25000,)\n",
      "b'Zero Day leads you to think, even re-think why two'\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array(train_data.data)\n",
    "y_train = np.array(train_data.target)\n",
    "x_test = np.array(test_data.data)\n",
    "y_test = np.array(test_data.target)\n",
    "\n",
    "print(x_train.shape)  # (25000,)\n",
    "print(y_train.shape)  # (25000, 1)\n",
    "print(x_train[0][:50])  # this film was just brilliant casting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "physical-oracle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfactory-birth",
   "metadata": {},
   "source": [
    "第二步是运行TextClassifier。 作为一个快速演示，我们将 epochs 设置为 2。您还可以为自适应数量的 epochs 保留未指定的 epochs。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "naval-annex",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 01m 03s]\n",
      "val_loss: 0.2718275785446167\n",
      "\n",
      "Best val_loss So Far: 0.2718275785446167\n",
      "Total elapsed time: 00h 01m 03s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/2\n",
      "782/782 [==============================] - 27s 33ms/step - loss: 0.4346 - accuracy: 0.7758\n",
      "Epoch 2/2\n",
      "782/782 [==============================] - 26s 33ms/step - loss: 0.2351 - accuracy: 0.9055\n",
      "INFO:tensorflow:Assets written to: ./text_classifier/best_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Initialize the text classifier.\n",
    "clf = ak.TextClassifier(\n",
    "    overwrite=True, max_trials=1\n",
    ")  # It only tries 1 model as a quick demo.\n",
    "# Feed the text classifier with training data.\n",
    "clf.fit(x_train, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "developmental-playing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 16s 20ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict with the best model.\n",
    "predicted_y = clf.predict(x_test)\n",
    "predicted_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "forced-satellite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 20s 26ms/step - loss: 0.2654 - accuracy: 0.8938\n",
      "[0.26544809341430664, 0.8938000202178955]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best model with testing data.\n",
    "print(clf.evaluate(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indian-nickname",
   "metadata": {},
   "source": [
    "## 验证数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-wisdom",
   "metadata": {},
   "source": [
    "默认情况下，AutoKeras 使用最后 20% 的训练数据作为验证数据。 如下例所示，您可以使用validation_split 来指定百分比。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "substantial-mentor",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    # Split the training data and use the last 15% as validation data.\n",
    "    validation_split=0.15,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ideal-qualification",
   "metadata": {},
   "source": [
    "您还可以使用自己的验证集，而不是使用`validation_data`将其从训练数据中分离出来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "focused-health",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 5000\n",
    "x_val = x_train[split:]\n",
    "y_val = y_train[split:]\n",
    "x_train = x_train[:split]\n",
    "y_train = y_train[:split]\n",
    "clf.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=2,\n",
    "    # Use your own validation set.\n",
    "    validation_data=(x_val, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focal-injection",
   "metadata": {},
   "source": [
    "## 自定义搜索空间"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-flour",
   "metadata": {},
   "source": [
    "对于高级用户，您可以使用 AutoModel 而不是 TextClassifier 自定义搜索空间。 您可以为一些高级配置配置 TextBlock，例如，针对要使用的文本矢量化方法类型的矢量化器。 您可以使用“sequence”，它使用 TextToInteSequence 将单词转换为整数并使用 Embedding 嵌入整数序列，或者您可以使用“ngram”，它使用 TextToNgramVector 对句子进行向量化。 您也可以不指定这些参数，这将使不同的选择自动调整。 有关详细信息，请参阅以下示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "taken-center",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 00m 14s]\n",
      "val_loss: 0.39885959029197693\n",
      "\n",
      "Best val_loss So Far: 0.39885959029197693\n",
      "Total elapsed time: 00h 00m 14s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/2\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.5026 - accuracy: 0.7582\n",
      "Epoch 2/2\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.1930 - accuracy: 0.9394\n",
      "INFO:tensorflow:Assets written to: ./auto_model/best_model/assets\n"
     ]
    }
   ],
   "source": [
    "input_node = ak.TextInput()\n",
    "output_node = ak.TextBlock(block_type=\"ngram\")(input_node)\n",
    "output_node = ak.ClassificationHead()(output_node)\n",
    "clf = ak.AutoModel(\n",
    "    inputs=input_node, outputs=output_node, overwrite=True, max_trials=1\n",
    ")\n",
    "clf.fit(x_train, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "knowing-architecture",
   "metadata": {},
   "source": [
    "AutoModel 的用法类似于 Keras 的函数式 API。 基本上，您正在构建一个图，其边是块，节点是块的中间输出。 使用 `output_node = ak.[some_block]([block_args])(input_node)` 添加从 `input_node` 到 `output_node` 的边。\n",
    "\n",
    "您甚至还可以使用更细粒度的块来进一步自定义搜索空间。 请参阅以下示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "pharmaceutical-mumbai",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 00m 15s]\n",
      "val_loss: 0.6931501030921936\n",
      "\n",
      "Best val_loss So Far: 0.6931501030921936\n",
      "Total elapsed time: 00h 00m 15s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/2\n",
      "157/157 [==============================] - 8s 43ms/step - loss: 0.6932 - accuracy: 0.4876\n",
      "Epoch 2/2\n",
      "157/157 [==============================] - 6s 38ms/step - loss: 0.6932 - accuracy: 0.4944\n",
      "INFO:tensorflow:Assets written to: ./auto_model/best_model/assets\n"
     ]
    }
   ],
   "source": [
    "input_node = ak.TextInput()\n",
    "output_node = ak.TextToIntSequence()(input_node)\n",
    "output_node = ak.Embedding()(output_node)\n",
    "# Use separable Conv layers in Keras.\n",
    "output_node = ak.ConvBlock(separable=True)(output_node)\n",
    "output_node = ak.ClassificationHead()(output_node)\n",
    "clf = ak.AutoModel(\n",
    "    inputs=input_node, outputs=output_node, overwrite=True, max_trials=1\n",
    ")\n",
    "clf.fit(x_train, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diverse-merit",
   "metadata": {},
   "source": [
    "## 数据格式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-grave",
   "metadata": {},
   "source": [
    "AutoKeras TextClassifier 对于数据格式非常灵活。\n",
    "\n",
    "对于文本，输入数据应该是一维的。对于分类标签，AutoKeras 接受普通标签，即字符串或整数，以及单热编码的编码标签，即 0 和 1 的向量。\n",
    "\n",
    "我们还支持对训练数据使用 tf.data.Dataset 格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "signed-eagle",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = tf.data.Dataset.from_tensor_slices(((x_train,), (y_train,))).batch(32)\n",
    "test_set = tf.data.Dataset.from_tensor_slices(((x_test,), (y_test,))).batch(32)\n",
    "\n",
    "clf = ak.TextClassifier(overwrite=True, max_trials=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "different-people",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 00m 21s]\n",
      "val_loss: 0.4119846224784851\n",
      "\n",
      "Best val_loss So Far: 0.4119846224784851\n",
      "Total elapsed time: 00h 00m 39s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/2\n",
      "157/157 [==============================] - 11s 58ms/step - loss: 0.6733 - accuracy: 0.5650\n",
      "Epoch 2/2\n",
      "157/157 [==============================] - 9s 58ms/step - loss: 0.4243 - accuracy: 0.8212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/public/huangwei/miniconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./text_classifier/best_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Feed the tensorflow Dataset to the classifier.\n",
    "clf.fit(train_set, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleased-sailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with the best model.\n",
    "predicted_y = clf.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-freeze",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best model with testing data.\n",
    "print(clf.evaluate(test_set))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
