{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "foreign-nickname",
   "metadata": {},
   "source": [
    "# 图像分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "defined-fitness",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "import autokeras as ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abroad-volunteer",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "\n",
    "if gpus:\n",
    "   \n",
    "    gpu0 = gpus[2] #如果有多个GPU，仅使用第0个GPU\n",
    "    tf.config.experimental.set_memory_growth(gpu0, True) #设置GPU显存用量按需使用\n",
    "    # 或者也可以设置GPU显存为固定使用量(例如：4G)\n",
    "    #tf.config.experimental.set_virtual_device_configuration(gpu0,\n",
    "    #    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)]) \n",
    "    tf.config.set_visible_devices([gpu0],\"GPU\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "charitable-cleanup",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exciting-shirt",
   "metadata": {},
   "source": [
    "## 一个简单例子"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "different-beast",
   "metadata": {},
   "source": [
    "第一步是准备数据。 这里我们以MNIST数据集为例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "scheduled-jacksonville",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "[5 0 4]\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(x_train.shape)  # (60000, 28, 28)\n",
    "print(y_train.shape)  # (60000,)\n",
    "print(y_train[:3])  # array([7, 2, 1], dtype=uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-acoustic",
   "metadata": {},
   "source": [
    "第二步是运行ImageClassifier。 建议对更复杂的数据集进行更多试验。 这只是 MNIST 的快速演示，因此我们将 max_trials 设置为 1。出于同样的原因，我们将 epochs 设置为 10。您也可以为自适应数量的 epochs 不指定 epochs。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ethical-martin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 04m 25s]\n",
      "val_loss: 0.03918910399079323\n",
      "\n",
      "Best val_loss So Far: 0.03918910399079323\n",
      "Total elapsed time: 00h 04m 25s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 25s 13ms/step - loss: 0.1584 - accuracy: 0.9508\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 25s 13ms/step - loss: 0.0745 - accuracy: 0.9771\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 25s 13ms/step - loss: 0.0582 - accuracy: 0.9821\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 25s 13ms/step - loss: 0.0503 - accuracy: 0.9842\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 25s 13ms/step - loss: 0.0446 - accuracy: 0.9861\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 25s 13ms/step - loss: 0.0420 - accuracy: 0.9863\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 25s 13ms/step - loss: 0.0365 - accuracy: 0.9886\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 25s 13ms/step - loss: 0.0370 - accuracy: 0.9883\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 25s 13ms/step - loss: 0.0317 - accuracy: 0.9900\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 25s 13ms/step - loss: 0.0302 - accuracy: 0.9902\n",
      "INFO:tensorflow:Assets written to: ./image_classifier/best_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Initialize the image classifier.\n",
    "clf = ak.ImageClassifier(overwrite=True, max_trials=1)\n",
    "# Feed the image classifier with training data.\n",
    "clf.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "killing-lighter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step\n",
      "[['7']\n",
      " ['2']\n",
      " ['1']\n",
      " ...\n",
      " ['4']\n",
      " ['5']\n",
      " ['6']]\n"
     ]
    }
   ],
   "source": [
    "# Predict with the best model.\n",
    "predicted_y = clf.predict(x_test)\n",
    "print(predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "attached-emerald",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 14ms/step - loss: 0.0362 - accuracy: 0.9891\n",
      "[0.036244697868824005, 0.9890999794006348]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best model with testing data.\n",
    "print(clf.evaluate(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-visit",
   "metadata": {},
   "source": [
    "## 验证数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closing-fault",
   "metadata": {},
   "source": [
    "默认情况下，AutoKeras 使用最后 20% 的训练数据作为验证数据。 如下例所示，您可以使用validation_split 来指定百分比。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "purple-damage",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    # Split the training data and use the last 15% as validation data.\n",
    "    validation_split=0.15,\n",
    "    epochs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-mozambique",
   "metadata": {},
   "source": [
    "您还可以使用自己的验证集，而不是使用validation_data 将其从训练数据中分离出来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "moved-silver",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 50000\n",
    "x_val = x_train[split:]\n",
    "y_val = y_train[split:]\n",
    "x_train = x_train[:split]\n",
    "y_train = y_train[:split]\n",
    "clf.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    # Use your own validation set.\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colonial-terminal",
   "metadata": {},
   "source": [
    "## 自定义搜索空间"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-antarctica",
   "metadata": {},
   "source": [
    "对于高级用户，您可以使用 AutoModel 而不是 ImageClassifier 来自定义您的搜索空间。 您可以为一些高级配置配置 ImageBlock，例如，block_type 为要搜索的神经网络类型，normalize 为是否进行数据归一化，augment 为是否进行数据增强。 您也可以不指定这些参数，这将使不同的选择自动调整。 有关详细信息，请参阅以下示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "proved-anime",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 31m 31s]\n",
      "val_loss: 0.09327429533004761\n",
      "\n",
      "Best val_loss So Far: 0.09327429533004761\n",
      "Total elapsed time: 00h 31m 31s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 210s 104ms/step - loss: 0.6322 - accuracy: 0.8437\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 195s 104ms/step - loss: 0.4301 - accuracy: 0.9044\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 194s 104ms/step - loss: 0.2932 - accuracy: 0.9477\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 193s 103ms/step - loss: 0.3473 - accuracy: 0.9196\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 191s 102ms/step - loss: 0.3149 - accuracy: 0.9367\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 193s 103ms/step - loss: 0.2574 - accuracy: 0.9401\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 193s 103ms/step - loss: 0.1488 - accuracy: 0.9639\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 190s 101ms/step - loss: 0.1159 - accuracy: 0.9725\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 193s 103ms/step - loss: 0.2943 - accuracy: 0.9339\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 189s 101ms/step - loss: 0.1240 - accuracy: 0.9680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/public/huangwei/miniconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./auto_model/best_model/assets\n"
     ]
    }
   ],
   "source": [
    "input_node = ak.ImageInput()\n",
    "output_node = ak.ImageBlock(\n",
    "    # Only search ResNet architectures.\n",
    "    block_type=\"resnet\",\n",
    "    # Normalize the dataset.\n",
    "    normalize=True,\n",
    "    # Do not do data augmentation.\n",
    "    augment=False,\n",
    ")(input_node)\n",
    "output_node = ak.ClassificationHead()(output_node)\n",
    "clf = ak.AutoModel(\n",
    "    inputs=input_node, outputs=output_node, overwrite=True, max_trials=1\n",
    ")\n",
    "clf.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coral-drill",
   "metadata": {},
   "source": [
    "AutoModel 的用法类似于 Keras 的函数式 API。 基本上，您正在构建一个图，其边是块，节点是块的中间输出。 使用 output_node = ak.some_block(input_node) 添加从 input_node 到 output_node 的边。\n",
    "\n",
    "您甚至还可以使用更细粒度的块来进一步自定义搜索空间。 请参阅以下示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "original-batman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 13m 18s]\n",
      "val_loss: 0.07811136543750763\n",
      "\n",
      "Best val_loss So Far: 0.07811136543750763\n",
      "Total elapsed time: 00h 13m 18s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 86s 43ms/step - loss: 0.3004 - accuracy: 0.9138\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 80s 43ms/step - loss: 0.1941 - accuracy: 0.9481\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 80s 43ms/step - loss: 0.1303 - accuracy: 0.9639\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 79s 42ms/step - loss: 0.1240 - accuracy: 0.9661\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 80s 43ms/step - loss: 0.0994 - accuracy: 0.9716\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 81s 43ms/step - loss: 0.0752 - accuracy: 0.9781\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 79s 42ms/step - loss: 0.0727 - accuracy: 0.9794\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 81s 43ms/step - loss: 0.0591 - accuracy: 0.9824\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 80s 43ms/step - loss: 0.0503 - accuracy: 0.9844\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 83s 44ms/step - loss: 0.0494 - accuracy: 0.9854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/public/huangwei/miniconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./auto_model/best_model/assets\n"
     ]
    }
   ],
   "source": [
    "input_node = ak.ImageInput()\n",
    "output_node = ak.Normalization()(input_node)\n",
    "output_node = ak.ImageAugmentation(horizontal_flip=False)(output_node)\n",
    "output_node = ak.ResNetBlock(version=\"v2\")(output_node)\n",
    "output_node = ak.ClassificationHead()(output_node)\n",
    "clf = ak.AutoModel(\n",
    "    inputs=input_node, outputs=output_node, overwrite=True, max_trials=1\n",
    ")\n",
    "clf.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "danish-layout",
   "metadata": {},
   "source": [
    "## 数据格式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollow-charity",
   "metadata": {},
   "source": [
    "AutoKeras ImageClassifier 对于数据格式非常灵活。\n",
    "\n",
    "对于图像，它接受带和不带通道维度的数据格式。 MNIST 数据集中的图像没有通道维度。 每个图像都是一个形状为 (28, 28) 的矩阵。 AutoKeras 也接受最终带有通道维度的三个维度的图像，例如 (32, 32, 3), (28, 28, 1)。\n",
    "\n",
    "对于分类标签，AutoKeras 接受普通标签（即字符串或整数）和单热编码标签（即 0 和 1 的向量）。\n",
    "\n",
    "因此，如果您按以下方式准备数据，ImageClassifier 应该仍然有效。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cooperative-royal",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Reshape the images to have the channel dimension.\n",
    "x_train = x_train.reshape(x_train.shape + (1,))\n",
    "x_test = x_test.reshape(x_test.shape + (1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "palestinian-gender",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the labels.\n",
    "eye = np.eye(10)\n",
    "y_train = eye[y_train]\n",
    "y_test = eye[y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "annoying-venice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(60000, 10)\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)  # (60000, 28, 28, 1)\n",
    "print(y_train.shape)  # (60000, 10)\n",
    "print(y_train[:3])\n",
    "# array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
    "#        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "#        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immune-taiwan",
   "metadata": {},
   "source": [
    "我们还支持对训练数据使用 tf.data.Dataset 格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "direct-christmas",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = tf.data.Dataset.from_tensor_slices(((x_train,), (y_train,)))\n",
    "test_set = tf.data.Dataset.from_tensor_slices(((x_test,), (y_test,)))\n",
    "\n",
    "clf = ak.ImageClassifier(overwrite=True, max_trials=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "flush-broad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 04m 17s]\n",
      "val_loss: 0.03819820284843445\n",
      "\n",
      "Best val_loss So Far: 0.03819820284843445\n",
      "Total elapsed time: 00h 04m 17s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.1591 - accuracy: 0.9517\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.0732 - accuracy: 0.9776\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.0584 - accuracy: 0.9820\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0525 - accuracy: 0.9832\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.0437 - accuracy: 0.9861\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.0403 - accuracy: 0.9871\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.0375 - accuracy: 0.9883\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.0343 - accuracy: 0.9889\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0328 - accuracy: 0.9895\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.0300 - accuracy: 0.9903\n",
      "INFO:tensorflow:Assets written to: ./image_classifier/best_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Feed the tensorflow Dataset to the classifier.\n",
    "clf.fit(train_set, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "detected-interval",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict with the best model.\n",
    "predicted_y = clf.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "reverse-laundry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 12ms/step - loss: 0.0312 - accuracy: 0.9903\n",
      "[0.031231015920639038, 0.9902999997138977]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best model with testing data.\n",
    "print(clf.evaluate(test_set))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
